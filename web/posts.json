[
  {
    "id": "introducing-hummbl-base120",
    "title": "Introducing HUMMBL Base120: 120 Mental Models as an API",
    "date": "2026-02-24",
    "author": "HUMMBL Team",
    "tags": ["announcement", "launch"],
    "excerpt": "We built the world's first mental models API. 120 models across 6 transformation types, organized into a structured framework called Base120. Here's why, and how to use it.",
    "body": "## Why Mental Models Need an API\n\nMental models are the most powerful thinking tools humans have developed. First Principles Thinking, Inversion, Systems Thinking, Pareto Analysis \u2014 these frameworks have driven decisions at companies from Amazon to SpaceX.\n\nBut they've always lived in books, blog posts, and people's heads. There's no structured, queryable way to access them programmatically. Until now.\n\n## What is Base120?\n\nBase120 is a taxonomy of 120 mental models organized into 6 transformation types:\n\n- **P (Perspective)** \u2014 See the problem differently\n- **IN (Inversion)** \u2014 Flip your thinking\n- **CO (Composition)** \u2014 Combine and integrate\n- **DE (Decomposition)** \u2014 Break it down\n- **RE (Recursion)** \u2014 Iterate and improve\n- **SY (Systems)** \u2014 See the big picture\n\nEach model has a code (like `P1` for First Principles Framing), a definition, usage guidance, and examples.\n\n## The API\n\nThe HUMMBL API is free, requires no authentication, and runs on Cloudflare's global edge network with sub-50ms response times.\n\n```bash\ncurl https://hummbl-api.hummbl.workers.dev/v1/recommend \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"problem\": \"How do I prioritize features for my MVP?\"}'\n```\n\nThe recommendation engine analyzes your problem statement, matches it against problem patterns, and returns the most relevant models with scores.\n\n## What's Next\n\nWe're building an MCP server for AI agent integration, adding workflow chains, and opening up community contributions. [Try it in the Playground](/playground.html) or [read the docs](/docs.html)."
  },
  {
    "id": "how-recommendation-engine-works",
    "title": "How the HUMMBL Recommendation Engine Actually Works",
    "date": "2026-02-20",
    "author": "HUMMBL Team",
    "tags": ["technical", "api"],
    "excerpt": "A deep dive into the keyword extraction, pattern matching, synonym expansion, and scoring algorithm behind the /v1/recommend endpoint.",
    "body": "## The Problem with \"Just Pick a Model\"\n\nWith 120 mental models, the paradox of choice is real. Telling someone to \"use First Principles Thinking\" for every problem is like telling a programmer to \"use a for loop\" for every algorithm. The right model depends on the problem.\n\n## Four-Stage Pipeline\n\nThe recommendation engine runs a four-stage pipeline on every request:\n\n### 1. Keyword Extraction\n\nWe strip stopwords (200+ common English words), apply a simple suffix-based stemmer, and extract meaningful terms. \"I'm struggling to prioritize features\" becomes `[struggl, priorit, featur]`.\n\n### 2. Synonym Expansion\n\nEach keyword is checked against a synonym map. \"struggling\" expands to include `blocked, stalled, halted, trapped, gridlocked`. This dramatically improves recall without sacrificing precision.\n\n### 3. Pattern Detection\n\nNine problem patterns scan the expanded keywords:\n- Perspective problems (reframing, bias, viewpoint)\n- Inversion problems (stuck, blocked, failure)\n- Composition problems (combine, integrate, team)\n- Decomposition problems (complex, prioritize, root cause)\n- Recursion problems (improve, iterate, feedback)\n- Systems problems (strategy, coordination, scale)\n- Decision problems (choose, tradeoff, uncertain)\n- Communication problems (explain, persuade, narrative)\n- Planning problems (roadmap, timeline, execute)\n\nEach pattern boosts the score of models in its transformation category.\n\n### 4. Model Scoring\n\nEvery model is scored against the expanded keywords and pattern boosts. The score combines keyword overlap with the model's name and definition, transformation category boosts from pattern matching, and a priority bonus for more fundamental models.\n\n## Try It\n\nThe entire pipeline runs in under 10ms on Cloudflare Workers. [Hit the playground](/playground.html) and watch the raw JSON tab to see scores in action."
  },
  {
    "id": "mental-models-for-ai-agents",
    "title": "Why AI Agents Need Mental Models",
    "date": "2026-02-16",
    "author": "HUMMBL Team",
    "tags": ["ai", "agents", "mcp"],
    "excerpt": "AI agents are great at execution but bad at framing. Mental models give them the structured thinking frameworks they're missing.",
    "body": "## The Execution Gap\n\nModern AI agents can write code, search the web, manage calendars, and coordinate with other agents. What they can't do well is **frame problems correctly**.\n\nAsk an AI to \"fix the bug\" and it'll try solutions. Ask it to first apply Root Cause Analysis (DE1) and Premortem (IN2), and it'll find the *right* solution faster.\n\n## MCP Integration\n\nThe HUMMBL MCP server gives any Claude, GPT, or compatible agent access to Base120:\n\n```bash\nnpx @hummbl/mcp-server\n```\n\nOnce connected, the agent can:\n- Search all 120 models by keyword or code\n- Get recommendations for a specific problem\n- Match problems to multi-step workflows\n- Chain models into transformation sequences\n\n## Real Example: Multi-Agent Coordination\n\nWe run 6 AI agents internally (Claude, Codex, Kimi, Gemini, Ollama, vendor-agnostic). When they started contradicting each other, we fed the problem into our own API:\n\n> \"We have 5 different AI agents but they keep duplicating work and contradicting each other.\"\n\nThe API recommended SY3 (Feedback Loops), CO5 (Coordination Protocols), P2 (Stakeholder Mapping), and SY15 (Multi-Scale Alignment). We implemented all four. Coordination improved dramatically.\n\n## The Meta-Insight\n\nThe most powerful thing about giving agents mental models isn't the models themselves \u2014 it's forcing the agent to **think about thinking** before acting. That metacognitive step is what separates good agents from great ones.\n\n[Read more in our case studies](/cases.html) or [explore the full model library](/explorer.html)."
  },
  {
    "id": "base120-security-stack",
    "title": "Building a 5-Layer Security Stack for a Public API",
    "date": "2026-02-10",
    "author": "HUMMBL Team",
    "tags": ["security", "technical"],
    "excerpt": "How we protect the HUMMBL API from prompt injection, PII leakage, and abuse \u2014 with zero authentication required on the free tier.",
    "body": "## The Challenge\n\nWe wanted the HUMMBL API to be completely open \u2014 no API keys, no signup, no friction. But \"open\" doesn't mean \"unprotected.\" A public API that accepts natural language input is a magnet for abuse.\n\n## 5 Layers of Defense\n\n### Layer 1: Input Validation\n18 prompt injection patterns detected and blocked. SQL injection, XSS, template injection, command injection, path traversal \u2014 all caught before the input reaches any logic.\n\n### Layer 2: PII Detection\n8 categories of personally identifiable information: SSNs, credit cards, emails, phone numbers, API keys, passwords, auth tokens, and private keys. Detected and stripped automatically.\n\n### Layer 3: Input Sanitization\nComment stripping, template literal neutralization, Unicode normalization. The input that reaches the recommendation engine is clean text.\n\n### Layer 4: Tool Permission Gate\nEvery internal tool has a defined permission level and rate limit. Even if an attacker bypasses input validation, the tools themselves enforce access control.\n\n### Layer 5: Output Validation\nBefore any response leaves the API, it's scanned for PII leakage, data exfiltration patterns, and size limits (50KB max). If the output looks suspicious, it's blocked.\n\n## Results\n\nSince launch: 0 security incidents, 0 PII leaks, 47 prompt injection attempts blocked. The entire stack runs in-line with <5ms overhead.\n\n[See it live on the Playground](/playground.html) \u2014 the Safety Stack section shows real-time stats."
  }
]
